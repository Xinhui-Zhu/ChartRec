{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: fetaqa, Size: 10297\n",
      "Split: table_op, Size: 11587\n",
      "Split: spider, Size: 3374\n",
      "Split: tatqa, Size: 8425\n",
      "Split: wikisql, Size: 28699\n",
      "Split: wtq, Size: 18216\n",
      "80598\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Features, Value\n",
    "\n",
    "# 定义预期的 schema\n",
    "features = Features({\n",
    "    \"prompt\": Value(\"string\"),\n",
    "    \"response\": Value(\"string\"),\n",
    "    \"csv_path\": Value(\"string\"),\n",
    "})\n",
    "\n",
    "# 加载数据集并指定 schema\n",
    "dataset = load_dataset(\"RUCKBReasoning/TableLLM-SFT\", features=features)\n",
    "ttl_size = 0\n",
    "for split, split_data in dataset.items():\n",
    "    print(f\"Split: {split}, Size: {len(split_data)}\")\n",
    "    ttl_size += len(split_data)\n",
    "print(ttl_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|██████████| 19661/19661 [00:00<00:00, 83385.62 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: train, Size: 19661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 加载数据集（以 \"imdb\" 数据集为例）\n",
    "dataset = load_dataset(\"Multilingual-Multimodal-NLP/TableInstruct\")\n",
    "# 打印数据集的大小\n",
    "for split, split_data in dataset.items():\n",
    "    print(f\"Split: {split}, Size: {len(split_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating test split: 100%|██████████| 3544/3544 [00:00<00:00, 92508.94 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: test, Size: 3544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# 加载数据集（以 \"imdb\" 数据集为例）\n",
    "dataset = load_dataset(\"Multilingual-Multimodal-NLP/TableBench\")\n",
    "# 打印数据集的大小\n",
    "for split, split_data in dataset.items():\n",
    "    print(f\"Split: {split}, Size: {len(split_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_placeholders(text):\n",
    "    # 定义正则表达式模式\n",
    "    patterns = {\n",
    "        \"table_description\": r\"### \\[Table Description\\]\\s*(.*?)\\s*### \\[Table\\]\",\n",
    "        \"table_in_csv\":  r\"### \\[Table\\]\\s*```(.*?)```\",\n",
    "        'csv_data': r\"Header and first few lines of CSV file:\\s*(.*?)\\s*Question:\",\n",
    "        'csv_data1': r\"Header and first few lines of CSV file 1:\\s*(.*?)\\s*Header and first few lines of CSV file 2:\",\n",
    "        'csv_data2': r\"Header and first few lines of CSV file 2:\\s*(.*?)\\s*Question:\",\n",
    "        \"question\": [\n",
    "            r\"### \\[Question\\]\\s*(.*?)\\s*### \\[Solution\\]\",\n",
    "            r\"Question:\\s*(.*)\"\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    extracted = {}\n",
    "\n",
    "    # 遍历 patterns 并处理单个模式和列表模式\n",
    "    for key, pattern in patterns.items():\n",
    "        if isinstance(pattern, list):  # 如果是列表模式\n",
    "            for sub_pattern in pattern:\n",
    "                match = re.search(sub_pattern, text, re.DOTALL)\n",
    "                if match:\n",
    "                    extracted[key] = match.group(1).strip()\n",
    "                    break  # 找到第一个匹配后停止\n",
    "        else:  # 如果是单个模式\n",
    "            match = re.search(pattern, text, re.DOTALL)\n",
    "            if match:\n",
    "                extracted[key] = match.group(1).strip()\n",
    "\n",
    "    return extracted\n",
    "\n",
    "# 示例字符串\n",
    "input_file = \"TableLLM-SFT/fetaqa.jsonl\"\n",
    "with open(input_file, 'r', encoding='utf-8') as infile:\n",
    "    for line in infile:\n",
    "        # Load each JSON line from the first dataset\n",
    "        text = json.loads(line.strip())[\"prompt\"]\n",
    "        print(text)\n",
    "        break\n",
    "            \n",
    "# 提取内容\n",
    "extracted_data = extract_placeholders(text)\n",
    "\n",
    "# 打印结果\n",
    "for key, value in extracted_data.items():\n",
    "    print(f\"{key}:\")\n",
    "    print(value)\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "movie_id,Title,Year,Director,Budget_million,Gross_worldwide\n",
      "1,The Boondock Saints,1999,Troy Duffy,6.0,30471\n",
      "2,The Big Kahuna,1999,John Swanbeck,7.0,3728888\n",
      "3,Storm Catcher,1999,Anthony Hickox,5.0,40500\n",
      "4,Jill Rips,2000,Anthony Hickox,4.0,456774\n",
      "5,The Whole Nine Yards,2000,Jonathan Lynn,41.3,106371651\n",
      "6,Battlefield Earth,2000,Roger Christian,44.0,29725663\n",
      "7,Get Carter,2000,Stephen Kay,63.6,19412993\n",
      "8,The Art of War,2000,Christian Duguay,60.0,40400425\n",
      "9,Agent Red,2000,Damian Lee,47.0,543356\n",
      "10,3000 Miles to Graceland,2001,Demian Lichtenstein,62.0,18720175\n",
      "\n",
      "You are a table analyst. Your task is to answer questions based on the table content. Offer a thorough and accurate solution that directly addresses the Question outlined in the [Question]. \n",
      "\n",
      "Read the table below in JSON format: \n",
      "[TABLE] \n",
      "{'columns': ['movie_id', 'Title', 'Year', 'Director', 'Budget_million', 'Gross_worldwide'], 'data': [['1', 'The Boondock Saints', '1999', 'Troy Duffy', '6.0', '30471'], ['2', 'The Big Kahuna', '1999', 'John Swanbeck', '7.0', '3728888'], ['3', 'Storm Catcher', '1999', 'Anthony Hickox', '5.0', '40500'], ['4', 'Jill Rips', '2000', 'Anthony Hickox', '4.0', '456774'], ['5', 'The Whole Nine Yards', '2000', 'Jonathan Lynn', '41.3', '106371651'], ['6', 'Battlefield Earth', '2000', 'Roger Christian', '44.0', '29725663'], ['7', 'Get Carter', '2000', 'Stephen Kay', '63.6', '19412993'], ['8', 'The Art of War', '2000', 'Christian Duguay', '60.0', '40400425'], ['9', 'Agent Red', '2000', 'Damian Lee', '47.0', '543356'], ['10', '3000 Miles to Graceland', '2001', 'Demian Lichtenstein', '62.0', '18720175']]} \n",
      "\n",
      "Let's get start! \n",
      "Question: Return the average, maximum, and minimum budgets in millions for movies made before the year 2000.\n",
      "Dataset converted and saved to TableLLM-SFT/spider_converted.jsonl\n",
      "Name,Circuit,Date,Winning driver,Winning constructor,Report\n",
      "Tripoli Grand Prix,Tripoli,11 March,Tazio Nuvolari,Bugatti,Report\n",
      "Circuit d'Esterel Plage,Saint-Raphaël,11 March,Louis Chiron,Bugatti,Report\n",
      "Pozzo Circuit,Pozzo,25 March,Tazio Nuvolari,Bugatti,Report\n",
      "Riviera Circuit,Cannes,1 April,Louis Chiron,Bugatti,Report\n",
      "Antibes Grand Prix,Garoupe,9 April,Louis Chiron,Bugatti,Report\n",
      "Alessandria Circuit,Alessandria,22 April,Tazio Nuvolari,Bugatti,Report\n",
      "Coppa Florio,Madonie,6 May,Albert Divo,Bugatti,Report\n",
      "Targa Florio,Madonie,6 May,Albert Divo,Bugatti,Report\n",
      "n Algeria Grand Prix,Staouéli,6 May,Marcel Lehoux,Bugatti,Report\n",
      "Messina Cup,Messina,13 May,Edwald Probst,Bugatti,Report\n",
      "\n",
      "You are a table analyst. Your task is to answer questions based on the table content. Offer a thorough and accurate solution that directly addresses the Question outlined in the [Question]. \n",
      "\n",
      "Read the table below in JSON format: \n",
      "[TABLE] \n",
      "{'columns': ['Name', 'Circuit', 'Date', 'Winning driver', 'Winning constructor', 'Report'], 'data': [['Tripoli Grand Prix', 'Tripoli', '11 March', 'Tazio Nuvolari', 'Bugatti', 'Report'], [\"Circuit d'Esterel Plage\", 'Saint-Raphaël', '11 March', 'Louis Chiron', 'Bugatti', 'Report'], ['Pozzo Circuit', 'Pozzo', '25 March', 'Tazio Nuvolari', 'Bugatti', 'Report'], ['Riviera Circuit', 'Cannes', '1 April', 'Louis Chiron', 'Bugatti', 'Report'], ['Antibes Grand Prix', 'Garoupe', '9 April', 'Louis Chiron', 'Bugatti', 'Report'], ['Alessandria Circuit', 'Alessandria', '22 April', 'Tazio Nuvolari', 'Bugatti', 'Report'], ['Coppa Florio', 'Madonie', '6 May', 'Albert Divo', 'Bugatti', 'Report'], ['Targa Florio', 'Madonie', '6 May', 'Albert Divo', 'Bugatti', 'Report'], ['n Algeria Grand Prix', 'Staouéli', '6 May', 'Marcel Lehoux', 'Bugatti', 'Report'], ['Messina Cup', 'Messina', '13 May', 'Edwald Probst', 'Bugatti', 'Report']]} \n",
      "\n",
      "Let's get start! \n",
      "Question: Which report includes a Circuit of Tripoli?\n",
      "Dataset converted and saved to TableLLM-SFT/wikisql_converted.jsonl\n",
      "Party,Votes,%,Seats,+/–\n",
      "Liberal Party,\"805,732\",54.7,73,–7\n",
      "Conservative Party,\"653,986\",44.4,58,+11\n",
      "Social Democratic Party,\"11,577\",0.8,0,–4\n",
      "People's Front,\"1,391\",0.1,0,–\n",
      "Invalid/blank votes,-,–,–,–\n",
      "Total,\"1,472,686\",100,131,0\n",
      "Registered voters/turnout,\"2,613,586\",-,–,–\n",
      "Source: Nohlen,Source: Nohlen,Source: Nohlen,Source: Nohlen,Source: Nohlen\n",
      "\n",
      "You are a table analyst. Your task is to answer questions based on the table content. Offer a thorough and accurate solution that directly addresses the Question outlined in the [Question]. \n",
      "\n",
      "Read the table below in JSON format: \n",
      "[TABLE] \n",
      "{'columns': ['Party', 'Votes', '%', 'Seats', '+/–'], 'data': [['Liberal Party', '805,732', '54.7', '73', '–7'], ['Conservative Party', '653,986', '44.4', '58', '+11'], ['Social Democratic Party', '11,577', '0.8', '0', '–4'], [\"People's Front\", '1,391', '0.1', '0', '–'], ['Invalid/blank votes', '-', '–', '–', '–'], ['Total', '1,472,686', '100', '131', '0'], ['Registered voters/turnout', '2,613,586', '-', '–', '–'], ['Source: Nohlen', 'Source: Nohlen', 'Source: Nohlen', 'Source: Nohlen', 'Source: Nohlen']]} \n",
      "\n",
      "Let's get start! \n",
      "Question: Who won the 1947 Colombian parliamentary election and how many seats did they win in the chamber?\n",
      "Dataset converted and saved to TableLLM-SFT/fetaqa_converted.jsonl\n",
      "You are a table analyst. Your task is to answer questions based on the table content. Offer a thorough and accurate solution that directly addresses the Question outlined in the [Question]. \n",
      "\n",
      "Read the table below in JSON format: \n",
      "[TABLE] \n",
      "{'columns': ['Year', 'Team', 'Games', 'Punt Return Attempts', 'Punt Return Yards', 'Punts Returned for Touchdown', 'Punts Fair Caught', 'Longest Punt Return', 'Kickoff Attempts', 'Kickoff Return Yards', 'Kickoffs Returned for Touchdown', 'Kickoffs Fair Caught', 'Longest Kickoff Return'], 'data': [['2008', 'DEN', '15', '14', '140', '0', '10', '36', '23', '600', '0', '0', '95'], ['2009', 'DEN', '14', '30', '335', '1', '13', '71', '26', '621', '1', '0', '93'], ['2010', 'DEN', '16', '25', '298', '0', '12', '33', '5', '107', '0', '0', '33'], ['2011', 'DEN', '12', '12', '194', '1', '9', '85', '3', '47', '0', '0', '20'], ['2012', 'SD', '10', '12', '64', '0', '2', '14', '0', '0', '0', '0', '0'], ['2013', 'SD', '15', '7', '41', '0', '7', '12', '0', '0', '0', '0', '0'], ['Total', 'Total', '82', '100', '1,072', '2', '53', '85', '57', '1375', '1', '0', '95']]} \n",
      "\n",
      "Let's get start! \n",
      "Question: How many punt returns were fair caught in total?\n",
      "Dataset converted and saved to TableLLM-SFT/wtq_converted.jsonl\n",
      "\"October 31,\",,\n",
      ",2019,2018\n",
      "(In thousands),,\n",
      "Parts and supplies,\"$33,617\",\"$28,287\"\n",
      "Prepaid insurance,\"8,859\",\"8,232\"\n",
      "Other prepaid expenses,\"14,455\",\"6,721\"\n",
      "Total prepaid expenses,\"$56,931\",\"$43,240\"\n",
      "\n",
      "You are a table analyst. Your task is to answer questions based on the table content. Offer a thorough and accurate solution that directly addresses the Question outlined in the [Question]. \n",
      "\n",
      "Read the table below in JSON format: \n",
      "[TABLE] \n",
      "{'columns': ['October 31,', '', ''], 'data': [['', '2019', '2018'], ['(In thousands)', '', ''], ['Parts and supplies', '$33,617', '$28,287'], ['Prepaid insurance', '8,859', '8,232'], ['Other prepaid expenses', '14,455', '6,721'], ['Total prepaid expenses', '$56,931', '$43,240']]} \n",
      "\n",
      "Let's get start! \n",
      "Question: What was the total value of prepaid expenses in 2018?\n",
      "Dataset converted and saved to TableLLM-SFT/tatqa_converted.jsonl\n",
      "sample,clinical_information,source_name,Assay Type,AvgSpotLen,Bases,BioProject,BioSample,Bytes,Center Name,Consent,DATASTORE filetype,DATASTORE provider,DATASTORE region,,Experiment,GEO_Accession (exp),gestational_age,Instrument,LibraryLayout,LibrarySelection,LibrarySource,Organism,Platform,ReleaseDate,Sample Name,SRA Study\n",
      "PHNPR0003,preeclampsia,Placenta,RNA-Seq,250,0,PRJNA0,SAMN0,1911697768,GEO,public,\"fastq,sra\",\"gs,ncbi,s3\",\"gs.US,ncbi.public,s3.us-east-1\",,SRX0,GSM0,0,Illumina HiSeq 2500,PAIRED,cDNA,TRANSCRIPTOMIC,Homo sapiens,ILLUMINA0,2020-04-22T00:00:00Z,GSM0,SRP0\n",
      "PHNPR0006,preeclampsia,Placenta,RNA-Seq,250,0,PRJNA0,SAMN0,1911697768,GEO,public,\"fastq,sra\",\"gs,ncbi,s3\",\"gs.US,ncbi.public,s3.us-east-1\",,SRX0,GSM0,0,Illumina HiSeq 2500,PAIRED,cDNA,TRANSCRIPTOMIC,Homo sapiens,ILLUMINA0,2020-04-22T00:00:00Z,GSM0,SRP0\n",
      "PHNPR0008,preeclampsia,Placenta,RNA-Seq,250,0,PRJNA0,SAMN0,1911697768,GEO,public,\"fastq,sra\",\"gs,ncbi,s3\",\"gs.US,ncbi.public,s3.us-east-1\",,SRX0,GSM0,0,Illumina HiSeq 2500,PAIRED,cDNA,TRANSCRIPTOMIC,Homo sapiens,ILLUMINA0,2020-04-22T00:00:00Z,GSM0,SRP0\n",
      "PHNPR0009,preeclampsia,Placenta,RNA-Seq,250,0,PRJNA0,SAMN0,1911697768,GEO,public,\"fastq,sra\",\"gs,ncbi,s3\",\"gs.US,ncbi.public,s3.us-east-1\",,SRX0,GSM0,0,Illumina HiSeq 2500,PAIRED,cDNA,TRANSCRIPTOMIC,Homo sapiens,ILLUMINA0,2020-04-22T00:00:00Z,GSM0,SRP0\n",
      "PHNPR0010,preeclampsia,Placenta,RNA-Seq,250,0,PRJNA0,SAMN0,1911697768,GEO,public,\"fastq,sra\",\"gs,ncbi,s3\",\"gs.US,ncbi.public,s3.us-east-1\",,SRX0,GSM0,0,Illumina HiSeq 2500,PAIRED,cDNA,TRANSCRIPTOMIC,Homo sapiens,ILLUMINA0,2020-04-22T00:00:00Z,GSM0,SRP0\n",
      "PHNPR0011,preeclampsia,Placenta,RNA-Seq,250,0,PRJNA0,SAMN0,1911697768,GEO,public,\"fastq,sra\",\"gs,ncbi,s3\",\"gs.US,ncbi.public,s3.us-east-1\",,SRX0,GSM0,0,Illumina HiSeq 2500,PAIRED,cDNA,TRANSCRIPTOMIC,Homo sapiens,ILLUMINA0,2020-04-22T00:00:00Z,GSM0,SRP0\n",
      "PHNPR0014,preeclampsia,Placenta,RNA-Seq,250,0,PRJNA0,SAMN0,1911697768,GEO,public,\"fastq,sra\",\"gs,ncbi,s3\",\"gs.US,ncbi.public,s3.us-east-1\",,SRX0,GSM0,0,Illumina HiSeq 2500,PAIRED,cDNA,TRANSCRIPTOMIC,Homo sapiens,ILLUMINA0,2020-04-22T00:00:00Z,GSM0,SRP0\n",
      "\n",
      "You are a table analyst. Your task is to answer questions based on the table content. Offer a thorough and accurate solution that directly addresses the Question outlined in the [Question]. \n",
      "\n",
      "Read the table below in JSON format: \n",
      "[TABLE] \n",
      "{'columns': ['sample', 'clinical_information', 'source_name', 'Assay Type', 'AvgSpotLen', 'Bases', 'BioProject', 'BioSample', 'Bytes', 'Center Name', 'Consent', 'DATASTORE filetype', 'DATASTORE provider', 'DATASTORE region', '', 'Experiment', 'GEO_Accession (exp)', 'gestational_age', 'Instrument', 'LibraryLayout', 'LibrarySelection', 'LibrarySource', 'Organism', 'Platform', 'ReleaseDate', 'Sample Name', 'SRA Study'], 'data': [['PHNPR0003', 'preeclampsia', 'Placenta', 'RNA-Seq', '250', '0', 'PRJNA0', 'SAMN0', '1911697768', 'GEO', 'public', 'fastq,sra', 'gs,ncbi,s3', 'gs.US,ncbi.public,s3.us-east-1', '', 'SRX0', 'GSM0', '0', 'Illumina HiSeq 2500', 'PAIRED', 'cDNA', 'TRANSCRIPTOMIC', 'Homo sapiens', 'ILLUMINA0', '2020-04-22T00:00:00Z', 'GSM0', 'SRP0'], ['PHNPR0006', 'preeclampsia', 'Placenta', 'RNA-Seq', '250', '0', 'PRJNA0', 'SAMN0', '1911697768', 'GEO', 'public', 'fastq,sra', 'gs,ncbi,s3', 'gs.US,ncbi.public,s3.us-east-1', '', 'SRX0', 'GSM0', '0', 'Illumina HiSeq 2500', 'PAIRED', 'cDNA', 'TRANSCRIPTOMIC', 'Homo sapiens', 'ILLUMINA0', '2020-04-22T00:00:00Z', 'GSM0', 'SRP0'], ['PHNPR0008', 'preeclampsia', 'Placenta', 'RNA-Seq', '250', '0', 'PRJNA0', 'SAMN0', '1911697768', 'GEO', 'public', 'fastq,sra', 'gs,ncbi,s3', 'gs.US,ncbi.public,s3.us-east-1', '', 'SRX0', 'GSM0', '0', 'Illumina HiSeq 2500', 'PAIRED', 'cDNA', 'TRANSCRIPTOMIC', 'Homo sapiens', 'ILLUMINA0', '2020-04-22T00:00:00Z', 'GSM0', 'SRP0'], ['PHNPR0009', 'preeclampsia', 'Placenta', 'RNA-Seq', '250', '0', 'PRJNA0', 'SAMN0', '1911697768', 'GEO', 'public', 'fastq,sra', 'gs,ncbi,s3', 'gs.US,ncbi.public,s3.us-east-1', '', 'SRX0', 'GSM0', '0', 'Illumina HiSeq 2500', 'PAIRED', 'cDNA', 'TRANSCRIPTOMIC', 'Homo sapiens', 'ILLUMINA0', '2020-04-22T00:00:00Z', 'GSM0', 'SRP0'], ['PHNPR0010', 'preeclampsia', 'Placenta', 'RNA-Seq', '250', '0', 'PRJNA0', 'SAMN0', '1911697768', 'GEO', 'public', 'fastq,sra', 'gs,ncbi,s3', 'gs.US,ncbi.public,s3.us-east-1', '', 'SRX0', 'GSM0', '0', 'Illumina HiSeq 2500', 'PAIRED', 'cDNA', 'TRANSCRIPTOMIC', 'Homo sapiens', 'ILLUMINA0', '2020-04-22T00:00:00Z', 'GSM0', 'SRP0'], ['PHNPR0011', 'preeclampsia', 'Placenta', 'RNA-Seq', '250', '0', 'PRJNA0', 'SAMN0', '1911697768', 'GEO', 'public', 'fastq,sra', 'gs,ncbi,s3', 'gs.US,ncbi.public,s3.us-east-1', '', 'SRX0', 'GSM0', '0', 'Illumina HiSeq 2500', 'PAIRED', 'cDNA', 'TRANSCRIPTOMIC', 'Homo sapiens', 'ILLUMINA0', '2020-04-22T00:00:00Z', 'GSM0', 'SRP0'], ['PHNPR0014', 'preeclampsia', 'Placenta', 'RNA-Seq', '250', '0', 'PRJNA0', 'SAMN0', '1911697768', 'GEO', 'public', 'fastq,sra', 'gs,ncbi,s3', 'gs.US,ncbi.public,s3.us-east-1', '', 'SRX0', 'GSM0', '0', 'Illumina HiSeq 2500', 'PAIRED', 'cDNA', 'TRANSCRIPTOMIC', 'Homo sapiens', 'ILLUMINA0', '2020-04-22T00:00:00Z', 'GSM0', 'SRP0']]} \n",
      "\n",
      "Let's get start! \n",
      "Question: Update the 'AvgSpotLen' column by doubling its value for every row where the 'Instrument' is 'Illumina HiSeq 2500' and the total 'Bytes' for such rows is in the top 25% of all Bytes values.\n",
      "Dataset converted and saved to TableLLM-SFT/table-op_converted.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def convert_format(input_path, output_path):\n",
    "    \"\"\"\n",
    "    Convert the format of the first dataset to match the format of the second dataset.\n",
    "    Args:\n",
    "        input_path (str): Path to the input JSONL file (first dataset).\n",
    "        output_path (str): Path to the output JSONL file (converted dataset).\n",
    "    \"\"\"\n",
    "    with open(input_path, 'r', encoding='utf-8') as infile, open(output_path, 'w', encoding='utf-8') as outfile:\n",
    "        for line in infile:\n",
    "            # Load each JSON line from the first dataset\n",
    "            original_example = json.loads(line.strip())\n",
    "            example = extract_placeholders(original_example[\"prompt\"])\n",
    "            \n",
    "            # Unified format\n",
    "            if 'csv_data' in example:  # Single table case\n",
    "                unified_example = {\n",
    "                    \"instruction\": f\"You are a data analyst proficient in Python. Below are the first few lines of a table. You need to write a Python program to solve the provided question. \\n\\nRead the table below in JSON format: \\n[TABLE] \\n{convert_csv_to_json(example['csv_data'])} \\n\\nLet's get start! \\nQuestion: {example['question']}\",\n",
    "                    \"response\": original_example[\"response\"],\n",
    "                }\n",
    "                outfile.write(json.dumps(unified_example, ensure_ascii=False) + '\\n')\n",
    "            elif 'csv_data1' in example and 'csv_data2' in example:  # Two table case\n",
    "                pass\n",
    "            elif 'table_in_csv' in example:  # Single table case\n",
    "                unified_example = {\n",
    "                    \"instruction\": f\"You are a table analyst. Your task is to answer questions based on the table content. Offer a thorough and accurate solution that directly addresses the Question outlined in the [Question]. \\n\\nRead the table below in JSON format: \\n[TABLE] \\n{convert_csv_to_json(example['table_in_csv'])} \\n\\nLet's get start! \\nQuestion: {example['question']}\",\n",
    "                    \"response\": original_example[\"response\"],\n",
    "                }\n",
    "                outfile.write(json.dumps(unified_example, ensure_ascii=False) + '\\n')\n",
    "        if 'csv_data' in example:  # Single table case\n",
    "            print(example[\"csv_data\"],end=\"\\n\\n\")\n",
    "        elif 'table_in_csv' in example:  # Single table case\n",
    "            print(example[\"table_in_csv\"],end=\"\\n\\n\")\n",
    "        print(unified_example[\"instruction\"])\n",
    "\n",
    "\n",
    "def convert_csv_to_json(csv_text):\n",
    "    # 初始化解析器，处理引号内的数据\n",
    "    reader = csv.reader(csv_text.strip().split(\"\\n\"), skipinitialspace=True)\n",
    "    \n",
    "    # 提取列名（第一行）\n",
    "    columns = next(reader)\n",
    "    \n",
    "    # 提取数据（后续行），并移除 \"\\r\" 和额外空白\n",
    "    data = []\n",
    "    for row in reader:\n",
    "        cleaned_row = [cell.strip().replace(\"\\r\", \"\") for cell in row]\n",
    "        data.append(cleaned_row)\n",
    "    \n",
    "    # 构造输出格式\n",
    "    converted = {\n",
    "        \"columns\": columns,\n",
    "        \"data\": data\n",
    "    }\n",
    "    return converted\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    for file in os.listdir(\"TableLLM-SFT\"):\n",
    "\n",
    "        input_file = f\"TableLLM-SFT/{file}\"\n",
    "        file_name=file.split(\".\")[0]\n",
    "        if file_name!=\"TableInstruct_instructions\" and \"converted\" not in file_name:\n",
    "            output_file = f\"TableLLM-SFT/{file_name}_converted.jsonl\"\n",
    "        \n",
    "            # Convert the dataset\n",
    "            convert_format(input_file, output_file)\n",
    "            print(f\"Dataset converted and saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a data analyst proficient in Python. Your task is to write executable Python code to analyze the table and then answer questions.\n",
      "\n",
      "[Guidelines]\n",
      "You should act following requirements below:\n",
      "1. based on the question, write out your analytical approach, and then write Python code according to this approach.\n",
      "2. The code needs to be concise and easy to understand, and if necessary, add comments for clarification.\n",
      "3. Code blocks need to strictly start with ```python and end with ```\n",
      "4. Your analysis must be based entirely on the above data. If the user's question is not related to data analysis, please politely refuse.\n",
      "5. You need to generate executable code. If there are results to be presented, please use the print function; if there are charts, please use the matplotlib library to draw them.\n",
      "6. Ensure to load the table with command ```df = pd.read_csv('table.csv')```\n",
      "\n",
      "\n",
      "The generated Python code should follow the format below, and ensure the first two code lines is exactly the same with the following code block:\n",
      "[Python Code Format]\n",
      "```python\n",
      "import pandas as pd \n",
      "df = pd.read_csv('table.csv')\n",
      "...\n",
      "print(f'Final Answer: {{answer}}')\n",
      "```\n",
      "\n",
      "Ensure the final answer is the last line in python code and can only be in the \"print(f'Final Answer: {{answer}}')\" form, no other from. Ensure variable \"answer\" can only be \"AnswerName1, AnswerName2...\" form, no other form, and \"AnswerName\" can only be a number or entity name, as short as possible, without any explanation.\n",
      "\n",
      "\n",
      "Let's think step by step and then generate python code to analyze table and present the final answer to the question.\n",
      "\n",
      "Read the table below in JSON format:\n",
      "[TABLE] \n",
      "{\"columns\": [\"Year\", \"Single\", \"Chart\", \"Position\"], \"data\": [[1986, \"\\\\Best of Both Worlds\\\\\\\"\\\"\", \"Album Rock Tracks\", 12], [1986, \"\\\\Dreams\\\\\\\"\\\"\", \"Album Rock Tracks\", 6], [1986, \"\\\\Dreams\\\\\\\"\\\"\", \"Billboard Hot 100\", 22], [1986, \"\\\\Love Walks In\\\\\\\"\\\"\", \"Album Rock Tracks\", 4], [1986, \"\\\\Love Walks In\\\\\\\"\\\"\", \"Billboard Hot 100\", 22], [1986, \"\\\\Summer Nights\\\\\\\"\\\"\", \"Album Rock Tracks\", 33], [1986, \"\\\\Why Can't This Be Love\\\\\\\"\\\"\", \"Album Rock Tracks\", 1], [1986, \"\\\\Why Can't This Be Love\\\\\\\"\\\"\", \"Billboard Hot 100\", 3]]}\n",
      "\n",
      "Let's get start!\n",
      "Question: How many singles by Van Halen reached the top 10 on the Album Rock Tracks chart in 1986?\n",
      "You are a data analyst proficient in Python. Your task is to write executable Python code to analyze the table and then answer questions.\n",
      "\n",
      "[Guidelines]\n",
      "You should act following requirements below:\n",
      "1. based on the question, write out your analytical approach, and then write Python code according to this approach.\n",
      "2. The code needs to be concise and easy to understand, and if necessary, add comments for clarification.\n",
      "3. Code blocks need to strictly start with ```python and end with ```\n",
      "4. Your analysis must be based entirely on the above data. If the user's question is not related to data analysis, please politely refuse.\n",
      "5. You need to generate executable code. If there are results to be presented, please use the print function; if there are charts, please use the matplotlib library to draw them.\n",
      "6. Ensure to load the table with command ```df = pd.read_csv('table.csv')```\n",
      "\n",
      "\n",
      "The generated Python code should follow the format below, and ensure the first two code lines is exactly the same with the following code block:\n",
      "[Python Code Format]\n",
      "```python\n",
      "import pandas as pd \n",
      "df = pd.read_csv('table.csv')\n",
      "...\n",
      "print(f'Final Answer: {{answer}}')\n",
      "```\n",
      "\n",
      "Ensure the final answer is the last line in python code and can only be in the \"print(f'Final Answer: {{answer}}')\" form, no other from. Ensure variable \"answer\" can only be \"AnswerName1, AnswerName2...\" form, no other form, and \"AnswerName\" can only be a number or entity name, as short as possible, without any explanation.\n",
      "\n",
      "\n",
      "Let's think step by step and then generate python code to analyze table and present the final answer to the question.\n",
      "\n",
      "Read the table below in JSON format:\n",
      "[TABLE] \n",
      "{\"columns\": [\"Planet\", \"Mass (MJ)\", \"Period (d)\", \"Semi-major axis (AU)\", \"Eccentricity\", \"Inclination (°)\", \"Year of discovery\"], \"data\": [[\"Gliese 876 d\", \"0.021\", \"1.938\", \"0.021\", \"0.2067\", \"50.201\", \"2005\"], [\"GJ 3634 b\", \"0.022\", \"2.646\", \"0.029\", \"0.0801\", \"58.683\", \"2011\"], [\"Gliese 581 e\", \"0.008\", \"3.149\", \"0.028\", \"0.0261\", \"50.537\", \"2009\"], [\"Tau Boötis b\", \"8.389\", \"3.312\", \"0.048\", \"0.0236\", \"150.521\", \"1996\"], [\"COROT-7c\", \"0.026\", \"3.698\", \"0.046\", \"0.0018\", \"78.206\", \"2009\"], [\"Upsilon Andromedae b\", \"1.266\", \"4.617\", \"0.059\", \"0.0226\", \"147.169\", \"1996\"], [\"Gliese 581 b\", \"0.059\", \"5.369\", \"0.041\", \"0.0159\", \"57.259\", \"2005\"], [\"Gliese 581 c\", \"0.021\", \"12.929\", \"0.073\", \"0.1674\", \"53.550\", \"2007\"], [\"HD 38529 Ab\", \"0.782\", \"14.310\", \"0.129\", \"0.2477\", \"123.331\", \"2000\"], [\"55 Cancri b\", \"1.030\", \"14.651\", \"0.118\", \"0.0096\", \"126.780\", \"1996\"], [\"Gliese 876 c\", \"0.714\", \"30.088\", \"0.131\", \"0.2559\", \"48.071\", \"2001\"], [\"55 Cancri c\", \"0.214\", \"44.364\", \"0.247\", \"0.0048\", \"53.241\", \"2002\"], [\"Gliese 876 b\", \"2.276\", \"61.117\", \"0.211\", \"0.0324\", \"83.929\", \"1998\"], [\"Gliese 581 d\", \"0.026\", \"66.800\", \"0.218\", \"0.3809\", \"58.257\", \"2007\"], [\"Gliese 876 e\", \"0.046\", \"124.262\", \"0.338\", \"0.0546\", \"120.548\", \"2010\"], [\"HD 60532 b\", \"3.150\", \"201.825\", \"0.761\", \"0.2776\", \"162.580\", \"2008\"], [\"Upsilon Andromedae c\", \"6.673\", \"237.746\", \"0.753\", \"0.2396\", \"16.746\", \"1999\"], [\"55 Cancri f\", \"0.190\", \"259.805\", \"0.804\", \"0.2963\", \"54.619\", \"2005\"], [\"Epsilon Reticuli b\", \"4.500\", \"415.241\", \"1.156\", \"0.0583\", \"17.403\", \"2000\"], [\"Iota Draconis b\", \"9.395\", \"511.098\", \"1.272\", \"0.7124\", \"69.920\", \"2002\"], [\"HD 147513 b\", \"1.268\", \"540.361\", \"1.265\", \"0.2577\", \"111.525\", \"2002\"], [\"Pollux b\", \"2.409\", \"589.636\", \"1.693\", \"0.0204\", \"90.684\", \"2006\"], [\"HD 60532 c\", \"7.457\", \"607.065\", \"1.586\", \"0.0383\", \"162.060\", \"2008\"], [\"Mu Arae b\", \"1.709\", \"643.252\", \"1.495\", \"0.1284\", \"78.867\", \"2000\"], [\"HD 128311 c\", \"3.215\", \"918.751\", \"1.720\", \"0.1709\", \"49.731\", \"2005\"], [\"HD 10647 b\", \"1.493\", \"1040.389\", \"2.055\", \"0.1632\", \"38.640\", \"2003\"], [\"Upsilon Andromedae d\", \"6.094\", \"1302.605\", \"2.527\", \"0.3181\", \"42.633\", \"1999\"], [\"HAT-P-17c\", \"1.416\", \"1797.885\", \"2.748\", \"0.0968\", \"77.217\", \"2010\"], [\"Epsilon Eridani b\", \"1.552\", \"2502.236\", \"3.383\", \"0.7021\", \"30.110\", \"2000\"], [\"55 Cancri d\", \"4.783\", \"5169.447\", \"5.901\", \"0.0141\", \"53.031\", \"2002\"]]}\n",
      "\n",
      "Let's get start!\n",
      "Question: What is the difference between the total mass (in MJ) of planets discovered between 2000 and 2005 and the total semi-major axis (in AU) of planets discovered between 2006 and 2010?\n",
      "You are a data analyst proficient in Python. Your task is to write executable Python code to analyze the table and then answer questions.\n",
      "\n",
      "[Guidelines]\n",
      "You should act following requirements below:\n",
      "1. based on the question, write out your analytical approach, and then write Python code according to this approach.\n",
      "2. The code needs to be concise and easy to understand, and if necessary, add comments for clarification.\n",
      "3. Code blocks need to strictly start with ```python and end with ```\n",
      "4. Your analysis must be based entirely on the above data. If the user's question is not related to data analysis, please politely refuse.\n",
      "5. You need to generate executable code. If there are results to be presented, please use the print function; if there are charts, please use the matplotlib library to draw them.\n",
      "6. Ensure to load the table with command ```df = pd.read_csv('table.csv')```\n",
      "\n",
      "\n",
      "The generated Python code should follow the format below, and ensure the first two code lines is exactly the same with the following code block:\n",
      "[Python Code Format]\n",
      "```python\n",
      "import pandas as pd \n",
      "df = pd.read_csv('table.csv')\n",
      "...\n",
      "print(f'Final Answer: {{answer}}')\n",
      "```\n",
      "\n",
      "Ensure the final answer is the last line in python code and can only be in the \"print(f'Final Answer: {{answer}}')\" form, no other from. Ensure variable \"answer\" can only be \"AnswerName1, AnswerName2...\" form, no other form, and \"AnswerName\" can only be a number or entity name, as short as possible, without any explanation.\n",
      "\n",
      "\n",
      "Let's think step by step and then generate python code to analyze table and present the final answer to the question.\n",
      "\n",
      "Read the table below in JSON format:\n",
      "[TABLE] \n",
      "{\"columns\": [\"Rank\", \"Nation\", \"Gold\", \"Silver\", \"Bronze\", \"Total\"], \"data\": [[1, \"Chinese Taipei (TPE)\", 2, 0, 0, 2], [1, \"Russia (RUS)\", 2, 0, 0, 2], [3, \"Great Britain (GBR)\", 1, 0, 0, 1], [4, \"Slovakia (SVK)\", 0, 2, 2, 4], [5, \"China (CHN)\", 0, 2, 1, 3], [6, \"Mexico (MEX)\", 0, 1, 1, 2], [7, \"Germany (GER)\", 0, 0, 2, 2], [8, \"South Korea (KOR)\", 0, 0, 1, 1], [8, \"Switzerland (SUI)\", 0, 0, 1, 1], [8, \"Thailand (THA)\", 0, 0, 1, 1], [8, \"Uzbekistan (UZB)\", 0, 0, 1, 1]]}\n",
      "\n",
      "Let's get start!\n",
      "Question: What is the difference in total medals between the nation with the highest total medals and the nation with the lowest total medals?**\n",
      "You are a data analyst proficient in Python. Your task is to write executable Python code to analyze the table and then answer questions.\n",
      "\n",
      "[Guidelines]\n",
      "You should act following requirements below:\n",
      "1. based on the question, write out your analytical approach, and then write Python code according to this approach.\n",
      "2. The code needs to be concise and easy to understand, and if necessary, add comments for clarification.\n",
      "3. Code blocks need to strictly start with ```python and end with ```\n",
      "4. Your analysis must be based entirely on the above data. If the user's question is not related to data analysis, please politely refuse.\n",
      "5. You need to generate executable code. If there are results to be presented, please use the print function; if there are charts, please use the matplotlib library to draw them.\n",
      "6. Ensure to load the table with command ```df = pd.read_csv('table.csv')```\n",
      "\n",
      "\n",
      "The generated Python code should follow the format below, and ensure the first two code lines is exactly the same with the following code block:\n",
      "[Python Code Format]\n",
      "```python\n",
      "import pandas as pd \n",
      "df = pd.read_csv('table.csv')\n",
      "...\n",
      "print(f'Final Answer: {{answer}}')\n",
      "```\n",
      "\n",
      "Ensure the final answer is the last line in python code and can only be in the \"print(f'Final Answer: {{answer}}')\" form, no other from. Ensure variable \"answer\" can only be \"AnswerName1, AnswerName2...\" form, no other form, and \"AnswerName\" can only be a number or entity name, as short as possible, without any explanation.\n",
      "\n",
      "\n",
      "Let's think step by step and then generate python code to analyze table and present the final answer to the question.\n",
      "\n",
      "Read the table below in JSON format:\n",
      "[TABLE] \n",
      "{\"columns\": [\"country\", \"area (km square)\", \"population (2011 est)\", \"population density (per km square)\", \"gdp (ppp) m usd\"], \"data\": [[\"country\", \"area (km square)\", \"population (2011 est)\", \"population density (per km square)\", \"gdp (ppp) m usd\"], [\"åland ( finland )\", \"1527\", \"28007\", \"18.1\", \"(finland)\"], [\"denmark\", \"43098\", \"5564219\", \"129\", \"204060\"], [\"faroe islands ( denmark )\", \"1399\", \"48917\", \"35.0\", \"(denmark)\"], [\"estonia\", \"45227\", \"1 286 479\", \"29\", \"29.944\"], [\"finland\", \"336897\", \"5374781\", \"16\", \"190862\"], [\"guernsey d\", \"78\", \"65573\", \"836.3\", \"2742\"], [\"iceland\", \"103001\", \"318452\", \"3.1\", \"12664\"], [\"ireland\", \"70273\", \"4581269\", \"65.2\", \"188112\"], [\"isle of man d\", \"572\", \"80085\", \"140\", \"2719\"], [\"jersey d\", \"116\", \"92500\", \"797\", \"5100\"], [\"latvia\", \"64589\", \"2067900\", \"34.3\", \"38764\"], [\"lithuania\", \"65200\", \"3221216\", \"50.3\", \"63625\"], [\"norway\", \"385252\", \"4905200\", \"15.1\", \"256523\"], [\"svalbard and jan mayen islands ( norway )\", \"61395\", \"2572\", \"0.042\", \"(norway)\"], [\"sweden\", \"449964\", \"9354462\", \"20.6\", \"381.719\"], [\"united kingdom\", \"243610\", \"62008048\", \"254.7\", \"2256830\"], [\"total\", \"1811176\", \"99230679\", \"54.8 / km square\", \"3591077\"]]}\n",
      "\n",
      "Let's get start!\n",
      "Question: What is the total GDP (in million USD) of countries with a population density greater than 50 per km square?\n"
     ]
    }
   ],
   "source": [
    "input_file = \"TableLLM-SFT/TableInstruct_instructions.jsonl\"\n",
    "n=0\n",
    "with open(input_file, 'r', encoding='utf-8') as infile:\n",
    "    for line in infile:\n",
    "        # Load each JSON line from the first dataset\n",
    "        text = json.loads(line.strip())[\"instruction\"]\n",
    "        print(text)\n",
    "        n+=1\n",
    "        if n>3: \n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
